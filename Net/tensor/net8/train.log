DEBUG:root:[ Iteration 0 ] Training loss: 0.173918
DEBUG:root:[ Iteration 0 ] Training loss: 0.168318
DEBUG:root:[ Iteration 0 ] Training loss: 0.166708
DEBUG:root:[ Iteration 0 ] Test loss: 0.178611
DEBUG:root:[ Iteration 3 ] Training loss: 0.16868
DEBUG:root:[ Iteration 6 ] Training loss: 0.169881
DEBUG:root:[ Iteration 9 ] Training loss: 0.170621
DEBUG:root:[ Iteration 12 ] Training loss: 0.168061
DEBUG:root:[ Iteration 15 ] Training loss: 0.160505
DEBUG:root:[ Iteration 18 ] Training loss: 0.153419
DEBUG:root:[ Iteration 20 ] Test loss: 0.156093
DEBUG:root:[ Iteration 21 ] Training loss: 0.16014
DEBUG:root:[ Iteration 24 ] Training loss: 0.15096
DEBUG:root:[ Iteration 27 ] Training loss: 0.147809
DEBUG:root:[ Iteration 30 ] Training loss: 0.134083
DEBUG:root:[ Iteration 33 ] Training loss: 0.107824
DEBUG:root:[ Iteration 36 ] Training loss: 0.107244
DEBUG:root:[ Iteration 39 ] Training loss: 0.117177
DEBUG:root:[ Iteration 40 ] Test loss: 0.121794
DEBUG:root:[ Iteration 42 ] Training loss: 0.119259
DEBUG:root:[ Iteration 45 ] Training loss: 0.1093
DEBUG:root:[ Iteration 48 ] Training loss: 0.132861
DEBUG:root:[ Iteration 51 ] Training loss: 0.1281
DEBUG:root:[ Iteration 54 ] Training loss: 0.108837
DEBUG:root:[ Iteration 57 ] Training loss: 0.122648
DEBUG:root:[ Iteration 60 ] Training loss: 0.118073
DEBUG:root:[ Iteration 60 ] Test loss: 0.113803
DEBUG:root:[ Iteration 63 ] Training loss: 0.117327
DEBUG:root:[ Iteration 66 ] Training loss: 0.11415
DEBUG:root:[ Iteration 69 ] Training loss: 0.107157
DEBUG:root:[ Iteration 72 ] Training loss: 0.105813
DEBUG:root:[ Iteration 75 ] Training loss: 0.107403
DEBUG:root:[ Iteration 78 ] Training loss: 0.101453
DEBUG:root:[ Iteration 80 ] Test loss: 0.105452
DEBUG:root:[ Iteration 81 ] Training loss: 0.128411
DEBUG:root:[ Iteration 84 ] Training loss: 0.117484
DEBUG:root:[ Iteration 87 ] Training loss: 0.116564
DEBUG:root:[ Iteration 90 ] Training loss: 0.112424
DEBUG:root:[ Iteration 93 ] Training loss: 0.112122
DEBUG:root:[ Iteration 96 ] Training loss: 0.114763
DEBUG:root:[ Iteration 99 ] Training loss: 0.0925398
DEBUG:root:[ Iteration 100 ] Test loss: 0.116665
DEBUG:root:[ Iteration 102 ] Training loss: 0.0956777
DEBUG:root:[ Iteration 105 ] Training loss: 0.116917
DEBUG:root:[ Iteration 108 ] Training loss: 0.108733
DEBUG:root:[ Iteration 111 ] Training loss: 0.114403
DEBUG:root:[ Iteration 114 ] Training loss: 0.103655
DEBUG:root:[ Iteration 117 ] Training loss: 0.106608
DEBUG:root:[ Iteration 120 ] Training loss: 0.114565
DEBUG:root:[ Iteration 120 ] Test loss: 0.106984
DEBUG:root:[ Iteration 123 ] Training loss: 0.116108
DEBUG:root:[ Iteration 126 ] Training loss: 0.100406
DEBUG:root:[ Iteration 129 ] Training loss: 0.117413
DEBUG:root:[ Iteration 132 ] Training loss: 0.124962
DEBUG:root:[ Iteration 135 ] Training loss: 0.108859
DEBUG:root:[ Iteration 138 ] Training loss: 0.127635
DEBUG:root:[ Iteration 140 ] Test loss: 0.134557
DEBUG:root:[ Iteration 141 ] Training loss: 0.119006
DEBUG:root:[ Iteration 144 ] Training loss: 0.113193
DEBUG:root:[ Iteration 147 ] Training loss: 0.115308
DEBUG:root:[ Iteration 150 ] Training loss: 0.12031
DEBUG:root:[ Iteration 153 ] Training loss: 0.112742
DEBUG:root:[ Iteration 156 ] Training loss: 0.106192
DEBUG:root:[ Iteration 159 ] Training loss: 0.10479
DEBUG:root:[ Iteration 160 ] Test loss: 0.117428
DEBUG:root:[ Iteration 162 ] Training loss: 0.110655
DEBUG:root:[ Iteration 165 ] Training loss: 0.114092
DEBUG:root:[ Iteration 168 ] Training loss: 0.124312
DEBUG:root:[ Iteration 171 ] Training loss: 0.114465
DEBUG:root:[ Iteration 174 ] Training loss: 0.128165
DEBUG:root:[ Iteration 177 ] Training loss: 0.124287
DEBUG:root:[ Iteration 180 ] Training loss: 0.105278
DEBUG:root:[ Iteration 180 ] Test loss: 0.104138
DEBUG:root:[ Iteration 183 ] Training loss: 0.105823
DEBUG:root:[ Iteration 186 ] Training loss: 0.109165
DEBUG:root:[ Iteration 189 ] Training loss: 0.118317
DEBUG:root:[ Iteration 192 ] Training loss: 0.107184
DEBUG:root:[ Iteration 195 ] Training loss: 0.116226
DEBUG:root:[ Iteration 198 ] Training loss: 0.102605
DEBUG:root:[ Iteration 200 ] Test loss: 0.114708
DEBUG:root:[ Iteration 201 ] Training loss: 0.124537
DEBUG:root:[ Iteration 204 ] Training loss: 0.109089
DEBUG:root:[ Iteration 207 ] Training loss: 0.10406
DEBUG:root:[ Iteration 210 ] Training loss: 0.109472
DEBUG:root:[ Iteration 213 ] Training loss: 0.087317
DEBUG:root:[ Iteration 216 ] Training loss: 0.130308
DEBUG:root:[ Iteration 219 ] Training loss: 0.113566
DEBUG:root:[ Iteration 220 ] Test loss: 0.106916
DEBUG:root:[ Iteration 222 ] Training loss: 0.110431
DEBUG:root:[ Iteration 225 ] Training loss: 0.113044
DEBUG:root:[ Iteration 228 ] Training loss: 0.122063
DEBUG:root:[ Iteration 231 ] Training loss: 0.105386
DEBUG:root:[ Iteration 234 ] Training loss: 0.115642
DEBUG:root:[ Iteration 237 ] Training loss: 0.12975
DEBUG:root:[ Iteration 240 ] Training loss: 0.103054
DEBUG:root:[ Iteration 240 ] Test loss: 0.108153
DEBUG:root:[ Iteration 243 ] Training loss: 0.102103
DEBUG:root:[ Iteration 246 ] Training loss: 0.123621
DEBUG:root:[ Iteration 249 ] Training loss: 0.126764
DEBUG:root:[ Iteration 252 ] Training loss: 0.122534
DEBUG:root:[ Iteration 255 ] Training loss: 0.123125
DEBUG:root:[ Iteration 258 ] Training loss: 0.100273
DEBUG:root:[ Iteration 260 ] Test loss: 0.112967
DEBUG:root:[ Iteration 261 ] Training loss: 0.11968
DEBUG:root:[ Iteration 264 ] Training loss: 0.109303
DEBUG:root:[ Iteration 267 ] Training loss: 0.134999
DEBUG:root:[ Iteration 270 ] Training loss: 0.105435
DEBUG:root:[ Iteration 273 ] Training loss: 0.109585
DEBUG:root:[ Iteration 276 ] Training loss: 0.117055
DEBUG:root:[ Iteration 279 ] Training loss: 0.11432
DEBUG:root:[ Iteration 280 ] Test loss: 0.123175
DEBUG:root:[ Iteration 282 ] Training loss: 0.125108
DEBUG:root:[ Iteration 285 ] Training loss: 0.114326
DEBUG:root:[ Iteration 288 ] Training loss: 0.0970335
DEBUG:root:[ Iteration 291 ] Training loss: 0.122766
DEBUG:root:[ Iteration 294 ] Training loss: 0.120614
DEBUG:root:[ Iteration 297 ] Training loss: 0.112936
DEBUG:root:[ Iteration 300 ] Training loss: 0.105416
DEBUG:root:[ Iteration 300 ] Test loss: 0.120237
DEBUG:root:[ Iteration 303 ] Training loss: 0.106367
DEBUG:root:[ Iteration 306 ] Training loss: 0.111945
DEBUG:root:[ Iteration 309 ] Training loss: 0.116611
DEBUG:root:[ Iteration 312 ] Training loss: 0.134589
DEBUG:root:[ Iteration 315 ] Training loss: 0.099941
DEBUG:root:[ Iteration 318 ] Training loss: 0.102709
DEBUG:root:[ Iteration 320 ] Test loss: 0.127337
DEBUG:root:[ Iteration 321 ] Training loss: 0.117514
DEBUG:root:[ Iteration 324 ] Training loss: 0.0990643
DEBUG:root:[ Iteration 327 ] Training loss: 0.116851
DEBUG:root:[ Iteration 330 ] Training loss: 0.117898
DEBUG:root:[ Iteration 333 ] Training loss: 0.104585
DEBUG:root:[ Iteration 336 ] Training loss: 0.110834
DEBUG:root:[ Iteration 339 ] Training loss: 0.119922
DEBUG:root:[ Iteration 340 ] Test loss: 0.124509
DEBUG:root:[ Iteration 342 ] Training loss: 0.123644
DEBUG:root:[ Iteration 345 ] Training loss: 0.102522
DEBUG:root:[ Iteration 348 ] Training loss: 0.107784
DEBUG:root:[ Iteration 351 ] Training loss: 0.119716
DEBUG:root:[ Iteration 354 ] Training loss: 0.10621
DEBUG:root:[ Iteration 357 ] Training loss: 0.111875
DEBUG:root:[ Iteration 360 ] Training loss: 0.122134
DEBUG:root:[ Iteration 360 ] Test loss: 0.118697
DEBUG:root:[ Iteration 363 ] Training loss: 0.107556
DEBUG:root:[ Iteration 366 ] Training loss: 0.102625
DEBUG:root:[ Iteration 369 ] Training loss: 0.103768
DEBUG:root:[ Iteration 372 ] Training loss: 0.106877
DEBUG:root:[ Iteration 375 ] Training loss: 0.108444
DEBUG:root:[ Iteration 378 ] Training loss: 0.0974285
DEBUG:root:[ Iteration 380 ] Test loss: 0.100689
DEBUG:root:[ Iteration 381 ] Training loss: 0.113891
DEBUG:root:[ Iteration 384 ] Training loss: 0.101381
DEBUG:root:[ Iteration 387 ] Training loss: 0.124406
DEBUG:root:[ Iteration 390 ] Training loss: 0.129532
DEBUG:root:[ Iteration 393 ] Training loss: 0.107546
DEBUG:root:[ Iteration 396 ] Training loss: 0.134543
DEBUG:root:[ Iteration 399 ] Training loss: 0.13673
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net8_02-16-2016_20h27m50s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.200622
DEBUG:root:[ Iteration 0 ] Test loss: 0.206029
DEBUG:root:[ Iteration 3 ] Training loss: 0.196009
DEBUG:root:[ Iteration 6 ] Training loss: 0.206763
DEBUG:root:[ Iteration 9 ] Training loss: 0.195411
DEBUG:root:[ Iteration 12 ] Training loss: 0.189514
DEBUG:root:[ Iteration 15 ] Training loss: 0.189261
DEBUG:root:[ Iteration 18 ] Training loss: 0.194028
DEBUG:root:[ Iteration 20 ] Test loss: 0.19004
DEBUG:root:[ Iteration 21 ] Training loss: 0.187174
DEBUG:root:[ Iteration 24 ] Training loss: 0.180625
DEBUG:root:[ Iteration 27 ] Training loss: 0.172507
DEBUG:root:[ Iteration 30 ] Training loss: 0.182871
DEBUG:root:[ Iteration 33 ] Training loss: 0.181838
DEBUG:root:[ Iteration 36 ] Training loss: 0.175941
DEBUG:root:[ Iteration 39 ] Training loss: 0.176689
DEBUG:root:[ Iteration 40 ] Test loss: 0.169841
DEBUG:root:[ Iteration 42 ] Training loss: 0.172225
DEBUG:root:[ Iteration 45 ] Training loss: 0.158116
DEBUG:root:[ Iteration 48 ] Training loss: 0.168859
DEBUG:root:[ Iteration 51 ] Training loss: 0.156986
DEBUG:root:[ Iteration 54 ] Training loss: 0.160654
DEBUG:root:[ Iteration 57 ] Training loss: 0.153768
DEBUG:root:[ Iteration 60 ] Training loss: 0.154761
DEBUG:root:[ Iteration 60 ] Test loss: 0.15489
DEBUG:root:[ Iteration 63 ] Training loss: 0.148881
DEBUG:root:[ Iteration 66 ] Training loss: 0.161061
DEBUG:root:[ Iteration 69 ] Training loss: 0.150776
DEBUG:root:[ Iteration 72 ] Training loss: 0.157022
DEBUG:root:[ Iteration 75 ] Training loss: 0.133771
DEBUG:root:[ Iteration 78 ] Training loss: 0.146994
DEBUG:root:[ Iteration 80 ] Test loss: 0.144797
DEBUG:root:[ Iteration 81 ] Training loss: 0.139113
DEBUG:root:[ Iteration 84 ] Training loss: 0.134574
DEBUG:root:[ Iteration 87 ] Training loss: 0.147093
DEBUG:root:[ Iteration 90 ] Training loss: 0.146477
DEBUG:root:[ Iteration 93 ] Training loss: 0.141325
DEBUG:root:[ Iteration 96 ] Training loss: 0.145465
DEBUG:root:[ Iteration 99 ] Training loss: 0.14911
DEBUG:root:[ Iteration 100 ] Test loss: 0.137571
DEBUG:root:[ Iteration 102 ] Training loss: 0.143482
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net8_02-19-2016_19h08m03s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.218919
DEBUG:root:[ Iteration 0 ] Test loss: 0.212999
DEBUG:root:[ Iteration 3 ] Training loss: 0.21126
DEBUG:root:[ Iteration 6 ] Training loss: 0.209182
DEBUG:root:[ Iteration 9 ] Training loss: 0.200384
DEBUG:root:[ Iteration 12 ] Training loss: 0.208141
DEBUG:root:[ Iteration 15 ] Training loss: 0.204809
DEBUG:root:[ Iteration 18 ] Training loss: 0.19483
DEBUG:root:[ Iteration 20 ] Test loss: 0.195571
DEBUG:root:[ Iteration 21 ] Training loss: 0.185543
DEBUG:root:[ Iteration 24 ] Training loss: 0.187141
DEBUG:root:[ Iteration 27 ] Training loss: 0.191156
DEBUG:root:[ Iteration 30 ] Training loss: 0.185245
DEBUG:root:[ Iteration 33 ] Training loss: 0.188268
DEBUG:root:[ Iteration 36 ] Training loss: 0.188458
DEBUG:root:[ Iteration 39 ] Training loss: 0.172844
DEBUG:root:[ Iteration 40 ] Test loss: 0.173927
DEBUG:root:[ Iteration 42 ] Training loss: 0.176005
DEBUG:root:[ Iteration 45 ] Training loss: 0.169281
DEBUG:root:[ Iteration 48 ] Training loss: 0.160791
DEBUG:root:[ Iteration 51 ] Training loss: 0.166875
DEBUG:root:[ Iteration 54 ] Training loss: 0.168835
DEBUG:root:[ Iteration 57 ] Training loss: 0.163998
DEBUG:root:[ Iteration 60 ] Training loss: 0.154747
DEBUG:root:[ Iteration 60 ] Test loss: 0.157813
DEBUG:root:[ Iteration 63 ] Training loss: 0.15932
DEBUG:root:[ Iteration 66 ] Training loss: 0.155596
DEBUG:root:[ Iteration 69 ] Training loss: 0.164219
DEBUG:root:[ Iteration 72 ] Training loss: 0.168232
DEBUG:root:[ Iteration 75 ] Training loss: 0.149612
DEBUG:root:[ Iteration 78 ] Training loss: 0.145179
DEBUG:root:[ Iteration 80 ] Test loss: 0.146713
DEBUG:root:[ Iteration 81 ] Training loss: 0.149238
DEBUG:root:[ Iteration 84 ] Training loss: 0.140837
DEBUG:root:[ Iteration 87 ] Training loss: 0.1425
DEBUG:root:[ Iteration 90 ] Training loss: 0.141583
DEBUG:root:[ Iteration 93 ] Training loss: 0.156054
DEBUG:root:[ Iteration 96 ] Training loss: 0.136725
DEBUG:root:[ Iteration 99 ] Training loss: 0.14144
DEBUG:root:[ Iteration 100 ] Test loss: 0.138983
DEBUG:root:[ Iteration 102 ] Training loss: 0.130821
DEBUG:root:[ Iteration 105 ] Training loss: 0.139962
DEBUG:root:[ Iteration 108 ] Training loss: 0.138955
DEBUG:root:[ Iteration 111 ] Training loss: 0.142445
DEBUG:root:[ Iteration 114 ] Training loss: 0.127701
DEBUG:root:[ Iteration 117 ] Training loss: 0.13631
DEBUG:root:[ Iteration 120 ] Training loss: 0.133103
DEBUG:root:[ Iteration 120 ] Test loss: 0.133491
DEBUG:root:[ Iteration 123 ] Training loss: 0.128313
DEBUG:root:[ Iteration 126 ] Training loss: 0.127998
DEBUG:root:[ Iteration 129 ] Training loss: 0.122778
DEBUG:root:[ Iteration 132 ] Training loss: 0.112297
DEBUG:root:[ Iteration 135 ] Training loss: 0.126902
DEBUG:root:[ Iteration 138 ] Training loss: 0.127362
DEBUG:root:[ Iteration 140 ] Test loss: 0.129444
DEBUG:root:[ Iteration 141 ] Training loss: 0.120051
DEBUG:root:[ Iteration 144 ] Training loss: 0.13312
DEBUG:root:[ Iteration 147 ] Training loss: 0.128853
DEBUG:root:[ Iteration 150 ] Training loss: 0.131317
DEBUG:root:[ Iteration 153 ] Training loss: 0.121635
DEBUG:root:[ Iteration 156 ] Training loss: 0.120844
DEBUG:root:[ Iteration 159 ] Training loss: 0.140947
DEBUG:root:[ Iteration 160 ] Test loss: 0.126454
DEBUG:root:[ Iteration 162 ] Training loss: 0.128708
DEBUG:root:[ Iteration 165 ] Training loss: 0.121158
DEBUG:root:[ Iteration 168 ] Training loss: 0.125348
DEBUG:root:[ Iteration 171 ] Training loss: 0.131584
DEBUG:root:[ Iteration 174 ] Training loss: 0.131765
DEBUG:root:[ Iteration 177 ] Training loss: 0.12406
DEBUG:root:[ Iteration 180 ] Training loss: 0.130575
DEBUG:root:[ Iteration 180 ] Test loss: 0.124122
DEBUG:root:[ Iteration 183 ] Training loss: 0.112161
DEBUG:root:[ Iteration 186 ] Training loss: 0.108105
DEBUG:root:[ Iteration 189 ] Training loss: 0.111651
DEBUG:root:[ Iteration 192 ] Training loss: 0.127315
DEBUG:root:[ Iteration 195 ] Training loss: 0.116716
DEBUG:root:[ Iteration 198 ] Training loss: 0.111291
DEBUG:root:[ Iteration 200 ] Test loss: 0.122201
DEBUG:root:[ Iteration 201 ] Training loss: 0.120781
DEBUG:root:[ Iteration 204 ] Training loss: 0.120424
DEBUG:root:[ Iteration 207 ] Training loss: 0.123632
DEBUG:root:[ Iteration 210 ] Training loss: 0.115738
DEBUG:root:[ Iteration 213 ] Training loss: 0.124808
DEBUG:root:[ Iteration 216 ] Training loss: 0.115524
DEBUG:root:[ Iteration 219 ] Training loss: 0.114017
DEBUG:root:[ Iteration 220 ] Test loss: 0.12074
DEBUG:root:[ Iteration 222 ] Training loss: 0.12557
DEBUG:root:[ Iteration 225 ] Training loss: 0.108099
DEBUG:root:[ Iteration 228 ] Training loss: 0.11748
DEBUG:root:[ Iteration 231 ] Training loss: 0.0982685
DEBUG:root:[ Iteration 234 ] Training loss: 0.124697
DEBUG:root:[ Iteration 237 ] Training loss: 0.130615
DEBUG:root:[ Iteration 240 ] Training loss: 0.127053
DEBUG:root:[ Iteration 240 ] Test loss: 0.119516
DEBUG:root:[ Iteration 243 ] Training loss: 0.116416
DEBUG:root:[ Iteration 246 ] Training loss: 0.139707
DEBUG:root:[ Iteration 249 ] Training loss: 0.109107
DEBUG:root:[ Iteration 252 ] Training loss: 0.109154
DEBUG:root:[ Iteration 255 ] Training loss: 0.126914
DEBUG:root:[ Iteration 258 ] Training loss: 0.117074
DEBUG:root:[ Iteration 260 ] Test loss: 0.118531
DEBUG:root:[ Iteration 261 ] Training loss: 0.125009
DEBUG:root:[ Iteration 264 ] Training loss: 0.13044
DEBUG:root:[ Iteration 267 ] Training loss: 0.108913
DEBUG:root:[ Iteration 270 ] Training loss: 0.135906
DEBUG:root:[ Iteration 273 ] Training loss: 0.135868
DEBUG:root:[ Iteration 276 ] Training loss: 0.12062
DEBUG:root:[ Iteration 279 ] Training loss: 0.109393
DEBUG:root:[ Iteration 280 ] Test loss: 0.117677
DEBUG:root:[ Iteration 282 ] Training loss: 0.127628
DEBUG:root:[ Iteration 285 ] Training loss: 0.130872
DEBUG:root:[ Iteration 288 ] Training loss: 0.122445
DEBUG:root:[ Iteration 291 ] Training loss: 0.135153
DEBUG:root:[ Iteration 294 ] Training loss: 0.125589
DEBUG:root:[ Iteration 297 ] Training loss: 0.11736
DEBUG:root:[ Iteration 300 ] Training loss: 0.112324
DEBUG:root:[ Iteration 300 ] Test loss: 0.116979
DEBUG:root:[ Iteration 303 ] Training loss: 0.122352
DEBUG:root:[ Iteration 306 ] Training loss: 0.0995586
DEBUG:root:[ Iteration 309 ] Training loss: 0.12
DEBUG:root:[ Iteration 312 ] Training loss: 0.122251
DEBUG:root:[ Iteration 315 ] Training loss: 0.105045
DEBUG:root:[ Iteration 318 ] Training loss: 0.113256
DEBUG:root:[ Iteration 320 ] Test loss: 0.11635
DEBUG:root:[ Iteration 321 ] Training loss: 0.111047
DEBUG:root:[ Iteration 324 ] Training loss: 0.121882
DEBUG:root:[ Iteration 327 ] Training loss: 0.123307
DEBUG:root:[ Iteration 330 ] Training loss: 0.113415
DEBUG:root:[ Iteration 333 ] Training loss: 0.102508
DEBUG:root:[ Iteration 336 ] Training loss: 0.112941
DEBUG:root:[ Iteration 339 ] Training loss: 0.108022
DEBUG:root:[ Iteration 340 ] Test loss: 0.115817
DEBUG:root:[ Iteration 342 ] Training loss: 0.108711
DEBUG:root:[ Iteration 345 ] Training loss: 0.126688
DEBUG:root:[ Iteration 348 ] Training loss: 0.112923
DEBUG:root:[ Iteration 351 ] Training loss: 0.110365
DEBUG:root:[ Iteration 354 ] Training loss: 0.121722
DEBUG:root:[ Iteration 357 ] Training loss: 0.116983
DEBUG:root:[ Iteration 360 ] Training loss: 0.124286
DEBUG:root:[ Iteration 360 ] Test loss: 0.115356
DEBUG:root:[ Iteration 363 ] Training loss: 0.138141
DEBUG:root:[ Iteration 366 ] Training loss: 0.113552
DEBUG:root:[ Iteration 369 ] Training loss: 0.114544
DEBUG:root:[ Iteration 372 ] Training loss: 0.102635
DEBUG:root:[ Iteration 375 ] Training loss: 0.106614
DEBUG:root:[ Iteration 378 ] Training loss: 0.115929
DEBUG:root:[ Iteration 380 ] Test loss: 0.114959
DEBUG:root:[ Iteration 381 ] Training loss: 0.118468
DEBUG:root:[ Iteration 384 ] Training loss: 0.106761
DEBUG:root:[ Iteration 387 ] Training loss: 0.124448
DEBUG:root:[ Iteration 390 ] Training loss: 0.130014
DEBUG:root:[ Iteration 393 ] Training loss: 0.103145
DEBUG:root:[ Iteration 396 ] Training loss: 0.121125
DEBUG:root:[ Iteration 399 ] Training loss: 0.123066
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net8_02-19-2016_19h17m28s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.203038
DEBUG:root:[ Iteration 0 ] Test loss: 0.208491
DEBUG:root:[ Iteration 3 ] Training loss: 0.207002
DEBUG:root:[ Iteration 6 ] Training loss: 0.209197
DEBUG:root:[ Iteration 9 ] Training loss: 0.206736
DEBUG:root:[ Iteration 12 ] Training loss: 0.199601
DEBUG:root:[ Iteration 15 ] Training loss: 0.199867
DEBUG:root:[ Iteration 18 ] Training loss: 0.19986
DEBUG:root:[ Iteration 20 ] Test loss: 0.191491
DEBUG:root:[ Iteration 21 ] Training loss: 0.193189
DEBUG:root:[ Iteration 24 ] Training loss: 0.198803
DEBUG:root:[ Iteration 27 ] Training loss: 0.180127
DEBUG:root:[ Iteration 30 ] Training loss: 0.181659
DEBUG:root:[ Iteration 33 ] Training loss: 0.172151
DEBUG:root:[ Iteration 36 ] Training loss: 0.177256
DEBUG:root:[ Iteration 39 ] Training loss: 0.169529
DEBUG:root:[ Iteration 40 ] Test loss: 0.167281
DEBUG:root:[ Iteration 42 ] Training loss: 0.169904
DEBUG:root:[ Iteration 45 ] Training loss: 0.156244
DEBUG:root:[ Iteration 48 ] Training loss: 0.156888
DEBUG:root:[ Iteration 51 ] Training loss: 0.121371
DEBUG:root:[ Iteration 54 ] Training loss: 0.107561
DEBUG:root:[ Iteration 57 ] Training loss: 0.114403
DEBUG:root:[ Iteration 60 ] Training loss: 0.0995813
DEBUG:root:[ Iteration 60 ] Test loss: 0.110128
DEBUG:root:[ Iteration 63 ] Training loss: 0.105533
DEBUG:root:[ Iteration 66 ] Training loss: 0.0922558
DEBUG:root:[ Iteration 69 ] Training loss: 0.132523
DEBUG:root:[ Iteration 72 ] Training loss: 0.104707
DEBUG:root:[ Iteration 75 ] Training loss: 0.109476
DEBUG:root:[ Iteration 78 ] Training loss: 0.0932413
DEBUG:root:[ Iteration 80 ] Test loss: 0.101841
DEBUG:root:[ Iteration 81 ] Training loss: 0.0830053
DEBUG:root:[ Iteration 84 ] Training loss: 0.0860123
DEBUG:root:[ Iteration 87 ] Training loss: 0.118128
DEBUG:root:[ Iteration 90 ] Training loss: 0.094007
DEBUG:root:[ Iteration 93 ] Training loss: 0.0845459
DEBUG:root:[ Iteration 96 ] Training loss: 0.0783943
DEBUG:root:[ Iteration 99 ] Training loss: 0.0701048
DEBUG:root:[ Iteration 100 ] Test loss: 0.0715289
DEBUG:root:[ Iteration 102 ] Training loss: 0.0376688
DEBUG:root:[ Iteration 105 ] Training loss: 0.0634418
DEBUG:root:[ Iteration 108 ] Training loss: 0.0218173
DEBUG:root:[ Iteration 111 ] Training loss: 0.0390012
DEBUG:root:[ Iteration 114 ] Training loss: 0.0354837
DEBUG:root:[ Iteration 117 ] Training loss: 0.0381737
DEBUG:root:[ Iteration 120 ] Training loss: 0.0707098
DEBUG:root:[ Iteration 120 ] Test loss: 0.0409458
DEBUG:root:[ Iteration 123 ] Training loss: 0.049571
DEBUG:root:[ Iteration 126 ] Training loss: 0.0322251
DEBUG:root:[ Iteration 129 ] Training loss: 0.0328726
DEBUG:root:[ Iteration 132 ] Training loss: 0.0585333
DEBUG:root:[ Iteration 135 ] Training loss: 0.0355184
DEBUG:root:[ Iteration 138 ] Training loss: 0.0136609
DEBUG:root:[ Iteration 140 ] Test loss: 0.0363198
DEBUG:root:[ Iteration 141 ] Training loss: 0.0356918
DEBUG:root:[ Iteration 144 ] Training loss: 0.0349085
DEBUG:root:[ Iteration 147 ] Training loss: 0.0393509
DEBUG:root:[ Iteration 150 ] Training loss: 0.0295779
DEBUG:root:[ Iteration 153 ] Training loss: 0.0490608
DEBUG:root:[ Iteration 156 ] Training loss: 0.0555687
DEBUG:root:[ Iteration 159 ] Training loss: 0.0301403
DEBUG:root:[ Iteration 160 ] Test loss: 0.0404384
DEBUG:root:[ Iteration 162 ] Training loss: 0.0363922
DEBUG:root:[ Iteration 165 ] Training loss: 0.0514934
DEBUG:root:[ Iteration 168 ] Training loss: 0.0293832
DEBUG:root:[ Iteration 171 ] Training loss: 0.0206674
DEBUG:root:[ Iteration 174 ] Training loss: 0.0378492
DEBUG:root:[ Iteration 177 ] Training loss: 0.0256588
DEBUG:root:[ Iteration 180 ] Training loss: 0.0439708
DEBUG:root:[ Iteration 180 ] Test loss: 0.0310684
DEBUG:root:[ Iteration 183 ] Training loss: 0.0254545
DEBUG:root:[ Iteration 186 ] Training loss: 0.0381669
DEBUG:root:[ Iteration 189 ] Training loss: 0.0234415
DEBUG:root:[ Iteration 192 ] Training loss: 0.0227838
DEBUG:root:[ Iteration 195 ] Training loss: 0.0340448
DEBUG:root:[ Iteration 198 ] Training loss: 0.027341
DEBUG:root:[ Iteration 200 ] Test loss: 0.0305466
DEBUG:root:[ Iteration 201 ] Training loss: 0.0129747
DEBUG:root:[ Iteration 204 ] Training loss: 0.0383884
DEBUG:root:[ Iteration 207 ] Training loss: 0.0437313
DEBUG:root:[ Iteration 210 ] Training loss: 0.0425866
DEBUG:root:[ Iteration 213 ] Training loss: 0.023523
DEBUG:root:[ Iteration 216 ] Training loss: 0.0225538
DEBUG:root:[ Iteration 219 ] Training loss: 0.0221682
DEBUG:root:[ Iteration 220 ] Test loss: 0.0303672
DEBUG:root:[ Iteration 222 ] Training loss: 0.0376705
DEBUG:root:[ Iteration 225 ] Training loss: 0.0225441
DEBUG:root:[ Iteration 228 ] Training loss: 0.0267697
DEBUG:root:[ Iteration 231 ] Training loss: 0.0418858
DEBUG:root:[ Iteration 234 ] Training loss: 0.0379818
DEBUG:root:[ Iteration 237 ] Training loss: 0.0679538
DEBUG:root:[ Iteration 240 ] Training loss: 0.0724889
DEBUG:root:[ Iteration 240 ] Test loss: 0.0302671
DEBUG:root:[ Iteration 243 ] Training loss: 0.0204004
DEBUG:root:[ Iteration 246 ] Training loss: 0.0300239
DEBUG:root:[ Iteration 249 ] Training loss: 0.00325753
DEBUG:root:[ Iteration 252 ] Training loss: 0.0330642
DEBUG:root:[ Iteration 255 ] Training loss: 0.050568
DEBUG:root:[ Iteration 258 ] Training loss: 0.022359
DEBUG:root:[ Iteration 260 ] Test loss: 0.0302068
DEBUG:root:[ Iteration 261 ] Training loss: 0.0343443
DEBUG:root:[ Iteration 264 ] Training loss: 0.0241455
DEBUG:root:[ Iteration 267 ] Training loss: 0.0310656
DEBUG:root:[ Iteration 270 ] Training loss: 0.0516044
DEBUG:root:[ Iteration 273 ] Training loss: 0.0267324
DEBUG:root:[ Iteration 276 ] Training loss: 0.0125015
DEBUG:root:[ Iteration 279 ] Training loss: 0.0447782
DEBUG:root:[ Iteration 280 ] Test loss: 0.0304313
DEBUG:root:[ Iteration 282 ] Training loss: 0.0474744
DEBUG:root:[ Iteration 285 ] Training loss: 0.043275
DEBUG:root:[ Iteration 288 ] Training loss: 0.0284879
DEBUG:root:[ Iteration 291 ] Training loss: 0.0177469
DEBUG:root:[ Iteration 294 ] Training loss: 0.0335819
DEBUG:root:[ Iteration 297 ] Training loss: 0.0430495
DEBUG:root:[ Iteration 300 ] Training loss: 0.0375931
DEBUG:root:[ Iteration 300 ] Test loss: 0.0302795
DEBUG:root:[ Iteration 303 ] Training loss: 0.0473283
DEBUG:root:[ Iteration 306 ] Training loss: 0.0420088
DEBUG:root:[ Iteration 309 ] Training loss: 0.026683
DEBUG:root:[ Iteration 312 ] Training loss: 0.0171513
DEBUG:root:[ Iteration 315 ] Training loss: 0.0264671
DEBUG:root:[ Iteration 318 ] Training loss: 0.00762087
DEBUG:root:[ Iteration 320 ] Test loss: 0.0297274
DEBUG:root:[ Iteration 321 ] Training loss: 0.0361628
DEBUG:root:[ Iteration 324 ] Training loss: 0.0125328
DEBUG:root:[ Iteration 327 ] Training loss: 0.0190788
DEBUG:root:[ Iteration 330 ] Training loss: 0.0329048
DEBUG:root:[ Iteration 333 ] Training loss: 0.0374441
DEBUG:root:[ Iteration 336 ] Training loss: 0.0221125
DEBUG:root:[ Iteration 339 ] Training loss: 0.03693
DEBUG:root:[ Iteration 340 ] Test loss: 0.0298435
DEBUG:root:[ Iteration 342 ] Training loss: 0.0171272
DEBUG:root:[ Iteration 345 ] Training loss: 0.0211488
DEBUG:root:[ Iteration 348 ] Training loss: 0.0370276
DEBUG:root:[ Iteration 351 ] Training loss: 0.0171242
DEBUG:root:[ Iteration 354 ] Training loss: 0.0260556
DEBUG:root:[ Iteration 357 ] Training loss: 0.0162677
DEBUG:root:[ Iteration 360 ] Training loss: 0.0184187
DEBUG:root:[ Iteration 360 ] Test loss: 0.0301253
DEBUG:root:[ Iteration 363 ] Training loss: 0.0382587
DEBUG:root:[ Iteration 366 ] Training loss: 0.0119758
DEBUG:root:[ Iteration 369 ] Training loss: 0.0438572
DEBUG:root:[ Iteration 372 ] Training loss: 0.0140058
DEBUG:root:[ Iteration 375 ] Training loss: 0.0296477
DEBUG:root:[ Iteration 378 ] Training loss: 0.0375752
DEBUG:root:[ Iteration 380 ] Test loss: 0.0297484
DEBUG:root:[ Iteration 381 ] Training loss: 0.0339761
DEBUG:root:[ Iteration 384 ] Training loss: 0.021303
DEBUG:root:[ Iteration 387 ] Training loss: 0.026563
DEBUG:root:[ Iteration 390 ] Training loss: 0.034149
DEBUG:root:[ Iteration 393 ] Training loss: 0.0277892
DEBUG:root:[ Iteration 396 ] Training loss: 0.0518082
DEBUG:root:[ Iteration 399 ] Training loss: 0.0267641
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net8_02-19-2016_23h49m00s.ckpt
DEBUG:root:Optimization done.
